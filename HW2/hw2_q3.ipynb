{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "from numpy import genfromtxt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 10)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "# get the data and the labels from csv and check the shapes\n",
    "X = genfromtxt(\"easier_data.csv\", delimiter=',')\n",
    "y = genfromtxt(\"label.csv\", delimiter=',')\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Part 1 (Linear Regression)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn score: 0.9991066310921242\n",
      "sklearn coefficients (linear): [-0.0027997   1.37760394  0.00368597 -0.0017419   0.33217045  1.01779495\n",
      "  1.38159824  1.01544405  0.33455298  0.35074258]\n",
      "\n",
      "Predicted: 12.43049081556034   Actual: 12.63\n",
      "Predicted: -8.543971099105637   Actual: -8.58\n",
      "Predicted: 1.8065647174071948   Actual: 1.98\n",
      "Predicted: -0.7486928677999032   Actual: -0.46\n",
      "Predicted: -5.145471632596664   Actual: -4.87\n",
      "Predicted: 6.764636193175818   Actual: 6.95\n",
      "Predicted: -4.758245413814564   Actual: -4.65\n",
      "Predicted: -10.963099656751453   Actual: -10.92\n",
      "Predicted: 16.568048955455254   Actual: 16.61\n",
      "Predicted: 3.222440576632188   Actual: 3.35\n",
      "Predicted: 2.3750065580620436   Actual: 2.39\n",
      "Predicted: -2.0929183237876394   Actual: -2.29\n",
      "Predicted: 10.287537268757923   Actual: 10.31\n",
      "Predicted: -2.352894625371654   Actual: -2.59\n",
      "Predicted: -8.122736000095326   Actual: -8.23\n",
      "Predicted: 2.2799343134813164   Actual: 2.49\n",
      "Predicted: 2.556958671482221   Actual: 2.63\n",
      "Predicted: 8.955758836572706   Actual: 8.61\n",
      "Predicted: -8.797148716926337   Actual: -9.07\n",
      "Predicted: -2.4768617153111023   Actual: -2.35\n",
      "\n",
      "Model score on test set: 0.9992976649558253\n",
      "Model error: 0.03747822852551159\n"
     ]
    }
   ],
   "source": [
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "# fitting the model\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "print(f'sklearn score: {reg.score(X_train, y_train)}')\n",
    "print(f'sklearn coefficients (linear): {reg.coef_}\\n')\n",
    "\n",
    "y_pred_linear = reg.predict(X_test)\n",
    "# print the first 20 test samples and true values\n",
    "for i in range(20):\n",
    "    print(f'Predicted: {y_pred_linear[i]}   Actual: {y_test[i]}')\n",
    "\n",
    "# errors\n",
    "print(f'\\nModel score on test set: {reg.score(X_test, y_test)}')\n",
    "print(f'Model error: {mean_squared_error(y_test, y_pred_linear)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 10)\n",
      "output coefficients: [-0.00769903  3.95904879  0.01059071 -0.00483846  0.98509411  2.95488417\n",
      "  3.99198557  2.9985356   0.96788702  1.01914286]\n",
      "\n",
      "Predicted: 11.568115815560814   Actual: 12.63\n",
      "Predicted: -9.406346099111014   Actual: -8.58\n",
      "Predicted: 0.9441897174059268   Actual: 1.98\n",
      "Predicted: -1.611067867800137   Actual: -0.46\n",
      "Predicted: -6.007846632605115   Actual: -4.87\n",
      "Predicted: 5.902261193189823   Actual: 6.95\n",
      "Predicted: -5.620620413824785   Actual: -4.65\n",
      "Predicted: -11.825474656756931   Actual: -10.92\n",
      "Predicted: 15.70567395544858   Actual: 16.61\n",
      "Predicted: 2.360065576644908   Actual: 3.35\n",
      "Predicted: 1.5126315580578371   Actual: 2.39\n",
      "Predicted: -2.9552933237892054   Actual: -2.29\n",
      "Predicted: 9.425162268742255   Actual: 10.31\n",
      "Predicted: -3.2152696253706585   Actual: -2.59\n",
      "Predicted: -8.985111000104522   Actual: -8.23\n",
      "Predicted: 1.4175593134783764   Actual: 2.49\n",
      "Predicted: 1.6945836714876759   Actual: 2.63\n",
      "Predicted: 8.093383836565126   Actual: 8.61\n",
      "Predicted: -9.659523716921454   Actual: -9.07\n",
      "Predicted: -3.339236715320564   Actual: -2.35\n",
      "\n",
      "mean squared error: 0.8491294415179335\n"
     ]
    }
   ],
   "source": [
    "# with built linear regression\n",
    "scaler = StandardScaler()\n",
    "X_train_linear = scaler.fit_transform(X_train)\n",
    "X_test_linear = scaler.transform(X_test)\n",
    "print(X_train_linear.shape)\n",
    "\n",
    "w_linear = utils.gradient_descent(X_train_linear, y_train, learning_rate=0.002, iters=20000)\n",
    "print(f\"output coefficients: {w_linear}\\n\")\n",
    "\n",
    "y_pred_linear = np.matmul(X_test_linear, w_linear)\n",
    "# print the first 20 predictions\n",
    "for i in range(20):\n",
    "    print(f'Predicted: {y_pred_linear[i]}   Actual: {y_test[i]}')\n",
    "\n",
    "# print the error\n",
    "print(f'\\nmean squared error: {mean_squared_error(y_test, y_pred_linear)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients: [-2.82039109e+01 -2.79970026e-03  1.37760394e+00  3.68597197e-03\n",
      " -1.74190380e-03  3.32170445e-01  1.01779495e+00  1.38159824e+00\n",
      "  1.01544405e+00  3.34552976e-01  3.50742582e-01]\n",
      "\n",
      "Predicted: 12.43049081556034   Actual: 12.63\n",
      "Predicted: -8.543971099105642   Actual: -8.58\n",
      "Predicted: 1.8065647174072148   Actual: 1.98\n",
      "Predicted: -0.7486928677998819   Actual: -0.46\n",
      "Predicted: -5.145471632596559   Actual: -4.87\n",
      "Predicted: 6.764636193175712   Actual: 6.95\n",
      "Predicted: -4.758245413814468   Actual: -4.65\n",
      "Predicted: -10.963099656751396   Actual: -10.92\n",
      "Predicted: 16.56804895545535   Actual: 16.61\n",
      "Predicted: 3.2224405766320894   Actual: 3.35\n",
      "Predicted: 2.3750065580621005   Actual: 2.39\n",
      "Predicted: -2.0929183237876594   Actual: -2.29\n",
      "Predicted: 10.287537268758108   Actual: 10.31\n",
      "Predicted: -2.3528946253717122   Actual: -2.59\n",
      "Predicted: -8.122736000095232   Actual: -8.23\n",
      "Predicted: 2.2799343134813226   Actual: 2.49\n",
      "Predicted: 2.556958671482166   Actual: 2.63\n",
      "Predicted: 8.955758836572821   Actual: 8.61\n",
      "Predicted: -8.797148716926381   Actual: -9.07\n",
      "Predicted: -2.4768617153109926   Actual: -2.35\n",
      "\n",
      "mean squared error: 0.0374782285255089\n"
     ]
    }
   ],
   "source": [
    "# Linear closed form solution\n",
    "phi = np.column_stack((np.ones(len(X_train)), X_train))\n",
    "w_closed = np.matmul(np.matmul(np.linalg.inv(np.matmul(np.transpose(phi), phi)), np.transpose(phi)), y_train)\n",
    "\n",
    "print(f'coefficients: {w_closed}\\n')\n",
    "\n",
    "X_test_closed = np.column_stack((np.ones(len(X_test)), X_test))\n",
    "y_pred_closed = np.matmul(X_test_closed, w_closed)\n",
    "\n",
    "# print the first 20 predictions\n",
    "for i in range(20):\n",
    "    print(f'Predicted: {y_pred_closed[i]}   Actual: {y_test[i]}')\n",
    "\n",
    "# print the error\n",
    "print(f'\\nmean squared error: {mean_squared_error(y_test, y_pred_closed)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comparing__\n",
    "\n",
    "The predictions for sklearn, my own gradient descent, and the closed form solution were all very similar, and all did very well against the true data points. However, my own gradient descent did significantly worse than the other two, with an error of about 0.84 while the others had errors under 0.05. Even so, most of the errors were small, as indicated by the mean squared error metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Part 2 (Polynomial Regression)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn score: 0.9992785463086552\n",
      "sklearn coefficients (linear): [-3.22318033e-02  1.34416635e+00  3.60219336e-02 -1.03705437e-02\n",
      "  3.62683756e-01  1.00994413e+00  1.41199967e+00  1.01951626e+00\n",
      "  3.17833189e-01  4.37396059e-01 -1.61484183e-03  1.12321079e-03\n",
      "  1.65168531e-03  9.60938169e-04  3.54511656e-03  1.13275062e-04\n",
      "  1.16923730e-03 -2.30558687e-04  3.14329788e-03 -1.94559398e-03\n",
      " -1.63249421e-04 -3.27788795e-04  3.73290074e-03  1.96245117e-03\n",
      " -1.92336384e-04  6.68916187e-04  1.22173367e-03  1.74503013e-03\n",
      " -3.42358407e-03 -4.77160522e-04 -1.38556312e-03 -2.25714922e-03\n",
      " -1.47455249e-03 -1.20087547e-03  2.55613954e-03 -1.21421290e-03\n",
      " -1.95522643e-03  3.57623497e-04 -3.52029139e-03 -1.22977370e-04\n",
      "  1.00292542e-03  2.95379260e-04  1.57373147e-03 -1.64749029e-03\n",
      " -3.11773433e-03  5.08785432e-03 -3.87928936e-03 -1.64359573e-04\n",
      " -1.36537691e-03  7.08882662e-04  1.65713780e-03 -1.87475585e-03\n",
      " -1.72119467e-03  1.60379661e-04 -1.47694530e-03 -1.09146949e-03\n",
      " -9.73710405e-04  8.70616334e-04  5.53466476e-04  8.04983534e-04\n",
      " -1.51118748e-03 -1.20793902e-03  2.69268675e-04 -9.44729401e-04\n",
      " -2.67072987e-03]\n",
      "\n",
      "Predicted: 12.507827157763707   Actual: 12.63\n",
      "Predicted: -8.52482820238438   Actual: -8.58\n",
      "Predicted: 1.64464271891109   Actual: 1.98\n",
      "Predicted: -0.6106581402559073   Actual: -0.46\n",
      "Predicted: -5.112585733362096   Actual: -4.87\n",
      "Predicted: 6.8245356840599385   Actual: 6.95\n",
      "Predicted: -4.598368479790235   Actual: -4.65\n",
      "Predicted: -10.819612706570442   Actual: -10.92\n",
      "Predicted: 16.504847415266156   Actual: 16.61\n",
      "Predicted: 3.377785874881482   Actual: 3.35\n",
      "Predicted: 2.4087807392417595   Actual: 2.39\n",
      "Predicted: -2.316386649920606   Actual: -2.29\n",
      "Predicted: 10.114113895984126   Actual: 10.31\n",
      "Predicted: -2.350803090345714   Actual: -2.59\n",
      "Predicted: -7.9137528813987466   Actual: -8.23\n",
      "Predicted: 2.3877513870580636   Actual: 2.49\n",
      "Predicted: 2.6618603977017337   Actual: 2.63\n",
      "Predicted: 8.917430289835806   Actual: 8.61\n",
      "Predicted: -8.801870325977681   Actual: -9.07\n",
      "Predicted: -2.33826117130117   Actual: -2.35\n",
      "\n",
      "Model score on test set: 0.9991022835734849\n",
      "Model error: 0.0479042326922142\n"
     ]
    }
   ],
   "source": [
    "# Quadratic regression with sklearn\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_quad = poly.fit_transform(X_train)\n",
    "X_test_quad = poly.transform(X_test)\n",
    "\n",
    "reg_quad = LinearRegression().fit(X_train_quad, y_train)\n",
    "print(f'sklearn score: {reg_quad.score(X_train_quad, y_train)}')\n",
    "print(f'sklearn coefficients (linear): {reg_quad.coef_}\\n')\n",
    "\n",
    "# printing the first 20 test samples for quadratic\n",
    "y_pred_quad = reg_quad.predict(X_test_quad)\n",
    "for i in range(20):\n",
    "    print(f'Predicted: {y_pred_quad[i]}   Actual: {y_test[i]}')\n",
    "\n",
    "print(f'\\nModel score on test set: {reg_quad.score(X_test_quad, y_test)}')\n",
    "print(f'Model error: {mean_squared_error(y_test, y_pred_quad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output coefficients: [-1.70643009e-01 -4.42092101e-01 -2.81700525e-01 -4.17437413e-01\n",
      " -4.12070514e-01 -3.69164976e-01 -3.38679793e-01 -3.25967176e-01\n",
      " -3.39568921e-01 -3.43887434e-01 -3.80073327e-01 -3.69938605e-02\n",
      "  2.54041071e-02 -8.03661229e-03 -6.61919430e-04  4.08715217e-02\n",
      " -1.05181886e-02  2.13348033e-02 -3.60809548e-05  4.60668160e-02\n",
      "  3.40922650e-02 -1.20906981e-02  4.68426361e-02  3.00032737e-02\n",
      "  5.35806528e-02  4.23521782e-02  4.60732871e-02  4.18647457e-02\n",
      "  3.07148278e-02  1.31845957e-02 -4.24344048e-02  1.78299453e-02\n",
      " -3.75666045e-04  1.85913793e-02  6.44748254e-03  2.15657892e-02\n",
      "  8.16010840e-03  3.87882228e-02 -4.81139092e-02  1.42388461e-02\n",
      "  2.85472389e-02  1.44754835e-02  3.40132285e-02  4.03184436e-03\n",
      "  1.12138314e-02 -5.49700140e-02  5.24739513e-02  3.35817987e-02\n",
      "  1.94330188e-02  1.09931576e-02  1.61340692e-03  7.13543764e-03\n",
      "  5.29891754e-02  1.36228392e-02  4.00238482e-02  7.50130558e-03\n",
      "  1.86277009e-02  5.58432150e-02  1.30573068e-02  3.66519825e-02\n",
      "  2.67912627e-03  3.20794702e-02  3.22206481e-02 -3.08618886e-02\n",
      " -1.15513903e-02 -1.68459333e-02]\n",
      "\n",
      "Predicted: 13.609732661316734   Actual: 12.63\n",
      "Predicted: -6.062144442381572   Actual: -8.58\n",
      "Predicted: 0.6000379882989053   Actual: 1.98\n",
      "Predicted: 2.022700312338162   Actual: -0.46\n",
      "Predicted: -5.322176519215672   Actual: -4.87\n",
      "Predicted: 3.761185372335937   Actual: 6.95\n",
      "Predicted: -5.128188772150971   Actual: -4.65\n",
      "Predicted: -10.580156369927986   Actual: -10.92\n",
      "Predicted: 17.632879070628153   Actual: 16.61\n",
      "Predicted: 1.3398465267845017   Actual: 3.35\n",
      "Predicted: 1.067064664278472   Actual: 2.39\n",
      "Predicted: -5.2079169959524725   Actual: -2.29\n",
      "Predicted: 8.875607020618267   Actual: 10.31\n",
      "Predicted: -2.8383592840366383   Actual: -2.59\n",
      "Predicted: -5.611343848015155   Actual: -8.23\n",
      "Predicted: 3.925500587644782   Actual: 2.49\n",
      "Predicted: 1.1608341259596409   Actual: 2.63\n",
      "Predicted: 10.767327424585915   Actual: 8.61\n",
      "Predicted: -7.788236493053609   Actual: -9.07\n",
      "Predicted: -2.3765947099712137   Actual: -2.35\n",
      "\n",
      "mean squared error: 3.8511566380667457\n"
     ]
    }
   ],
   "source": [
    "# with built polynomial (quadratic) regression\n",
    "poly = PolynomialFeatures(2)\n",
    "X_train_quad = poly.fit_transform(X_train)\n",
    "X_test_quad = poly.transform(X_test)\n",
    "\n",
    "# I dont think I should have this many iterations... but the function wouldnt work with a larger learning rate\n",
    "w_quad = utils.gradient_descent(X_train_quad, y_train, learning_rate=0.00001, iters=40000)\n",
    "print(f\"output coefficients: {w_quad}\\n\")\n",
    "\n",
    "y_pred_quad = np.matmul(X_test_quad, w_quad)\n",
    "# print the first 20 predictions\n",
    "for i in range(20):\n",
    "    print(f'Predicted: {y_pred_quad[i]}   Actual: {y_test[i]}')\n",
    "\n",
    "# print the error (definitely overfitting here or something)\n",
    "print(f'\\nmean squared error: {mean_squared_error(y_test, y_pred_quad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients: [-2.83946202e+01 -3.22318033e-02  1.34416635e+00  3.60219336e-02\n",
      " -1.03705437e-02  3.62683756e-01  1.00994413e+00  1.41199967e+00\n",
      "  1.01951626e+00  3.17833189e-01  4.37396059e-01 -1.61484183e-03\n",
      "  1.12321079e-03  1.65168531e-03  9.60938169e-04  3.54511656e-03\n",
      "  1.13275062e-04  1.16923730e-03 -2.30558687e-04  3.14329788e-03\n",
      " -1.94559398e-03 -1.63249421e-04 -3.27788795e-04  3.73290074e-03\n",
      "  1.96245117e-03 -1.92336384e-04  6.68916187e-04  1.22173367e-03\n",
      "  1.74503013e-03 -3.42358407e-03 -4.77160522e-04 -1.38556312e-03\n",
      " -2.25714922e-03 -1.47455249e-03 -1.20087547e-03  2.55613954e-03\n",
      " -1.21421290e-03 -1.95522643e-03  3.57623497e-04 -3.52029139e-03\n",
      " -1.22977370e-04  1.00292542e-03  2.95379260e-04  1.57373147e-03\n",
      " -1.64749029e-03 -3.11773433e-03  5.08785432e-03 -3.87928936e-03\n",
      " -1.64359573e-04 -1.36537691e-03  7.08882662e-04  1.65713780e-03\n",
      " -1.87475585e-03 -1.72119467e-03  1.60379661e-04 -1.47694530e-03\n",
      " -1.09146949e-03 -9.73710405e-04  8.70616334e-04  5.53466476e-04\n",
      "  8.04983534e-04 -1.51118748e-03 -1.20793902e-03  2.69268675e-04\n",
      " -9.44729401e-04 -2.67072987e-03]\n",
      "\n",
      "Predicted: 12.507827157764375   Actual: 12.63\n",
      "Predicted: -8.52482820238418   Actual: -8.58\n",
      "Predicted: 1.6446427189107613   Actual: 1.98\n",
      "Predicted: -0.6106581402551085   Actual: -0.46\n",
      "Predicted: -5.1125857333608575   Actual: -4.87\n",
      "Predicted: 6.824535684059463   Actual: 6.95\n",
      "Predicted: -4.5983684797895   Actual: -4.65\n",
      "Predicted: -10.819612706570158   Actual: -10.92\n",
      "Predicted: 16.504847415265132   Actual: 16.61\n",
      "Predicted: 3.3777858748822736   Actual: 3.35\n",
      "Predicted: 2.4087807392407785   Actual: 2.39\n",
      "Predicted: -2.316386649919565   Actual: -2.29\n",
      "Predicted: 10.114113895983822   Actual: 10.31\n",
      "Predicted: -2.3508030903447374   Actual: -2.59\n",
      "Predicted: -7.913752881398412   Actual: -8.23\n",
      "Predicted: 2.387751387059242   Actual: 2.49\n",
      "Predicted: 2.6618603977019837   Actual: 2.63\n",
      "Predicted: 8.917430289835766   Actual: 8.61\n",
      "Predicted: -8.801870325976688   Actual: -9.07\n",
      "Predicted: -2.3382611713004775   Actual: -2.35\n",
      "\n",
      "mean squared error: 0.047904232692344846\n"
     ]
    }
   ],
   "source": [
    "# Quadratic with closed form\n",
    "phi_quad = np.column_stack((np.ones(len(X_train_quad)), X_train_quad))\n",
    "w_closed_quad = np.matmul(np.matmul(np.linalg.inv(np.matmul(phi_quad.T, phi_quad)), phi_quad.T), y_train)\n",
    "\n",
    "print(f'coefficients: {w_closed_quad}\\n')\n",
    "\n",
    "X_test_closed_quad = np.column_stack((np.ones(len(X_test_quad)), X_test_quad))\n",
    "y_pred_closed_quad = np.matmul(X_test_closed_quad, w_closed_quad)\n",
    "\n",
    "# print the first 20 predictions\n",
    "for i in range(20):\n",
    "    print(f'Predicted: {y_pred_closed_quad[i]}   Actual: {y_test[i]}')\n",
    "\n",
    "# print the error\n",
    "print(f'\\nmean squared error: {mean_squared_error(y_test, y_pred_closed_quad)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comparing__\n",
    "\n",
    "The predictions for sklearn and the closed form solution were all very similar, and all did very well against the true data points. However, my own gradient descent did not work, and I kept getting errors when running the gradient descent. Even so, most of the errors for the models that did work were small, as indicated by the mean squared error metric."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
